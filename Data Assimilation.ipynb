{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "## Table of Contents\n",
    "###  [1.Pre-Processing](pre-processing.ipynb)\n",
    "###  [2.Data Assimilation](Data Assimilation.ipynb)\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\">\n",
    "   <ul class=\"toc-item\" id=\"toc-level0\">\n",
    "      <li><span><a href='#part 2.1' data-toc-modified-id=\"part 1\"><span class=\"toc-item-num\">&nbsp;&nbsp;</span>2.1 Submit batch job</a></span></li>\n",
    "      <li><span><a href='#part 2.2' data-toc-modified-id=\"part 2\"><span class=\"toc-item-num\">&nbsp;&nbsp;</span>2.2 Input Setting</a></span></li>\n",
    "      <li><span><a href='#part 2.3' data-toc-modified-id=\"part 3\"><span class=\"toc-item-num\">&nbsp;&nbsp;</span>2.3 Configuration </a></span></li>\n",
    "      <li><span><a href='#part 2.4' data-toc-modified-id=\"part 4\"><span class=\"toc-item-num\">&nbsp;&nbsp;</span>2.4 ES-MDA Workflow </a></span></li>\n",
    "      <li><span><a href='#part 2.5' data-toc-modified-id=\"part 4\"><span class=\"toc-item-num\">&nbsp;&nbsp;</span>2.5 PFLOTRAN related functions </a></span></li>  \n",
    "</div>\n",
    "###  [3.Post-Processing](post-processing.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part 2.1'></a>\n",
    "# 2.1 Submit batch job\n",
    "The shell script located at ./src can be submmited to Cori in National Energy Research Scientific Computing Center(NERSC) without modification using the sample data. This script needs to be modified to accommodate other super computers.      "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/bin/bash -l\n",
    "#SBATCH -A m1800\n",
    "#SBATCH -q regular\n",
    "#SBATCH -N 2\n",
    "#SBATCH -t 6:00:00\n",
    "#SBATCH -L SCRATCH\n",
    "#SBATCH -J 14_23_1\n",
    "#SBATCH -C haswell\n",
    "\n",
    "module load python/3.6-anaconda-4.4\n",
    "cd py_BC14_Obs23_iter4\n",
    "python src/esmda.py;\n",
    "wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following sections describes the implementation of the entire workflow by using ES-MDA method to estimate hydrologic exchange flux and associated functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part 2.2'></a>\n",
    "# 2.2 Input Setting \n",
    "The inputs are entered in user_specified_parameters.txt located at ./src. All theose parameters can be modified to accomadate the users.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# configure the ES-MDA scheme.\n",
    "nreaz = 100 # number of realizations\n",
    "ncore = 100 # number of realizations, equal to the number of realizations in this case as the 1D hydro-thermal model is simple\n",
    "niter = 4 # number of iterations\n",
    "alpha = 4 # inflation coefficients, equal to the number of iterations\n",
    "obs_sd_ratio = 0.04 # ratio of observation disturbance to the observation value\n",
    "da_interval = 3600 # time interval for data assimilation \n",
    "\n",
    "# configure 1-D hydro-thermal forward model\n",
    "hz = 0.65 # unit: m, height of the 1-D column\n",
    "dz = 0.01 # unit: m, grid dimension, usually 0.01 m \n",
    "w_den = 1000 # unit: m3/kg, water density\n",
    "w_vis = 0.001 # unit: kg/(m*s)-1, water viscosity\n",
    "g = 9.81 # unit: m/s2, gravitational constant\n",
    "porosity = 0.43 # unit: NA, porocity\n",
    "\n",
    "# configure observation points and path to data file \n",
    "obs_coord = [-0.2] # depth of observation point below the top boundary \n",
    "path_to_obs_data = 'dainput/obs.dat' # path to the observation data file, default path is './dainpput' \n",
    "\n",
    "# configure prior permability field\n",
    "hy_cond_mean = 20 # unit: m/d, mean of prior hydraulic conductivity\n",
    "hy_cond_sd = 5 # unit: m/d, S.D. of prior hyddraulic conductivity\n",
    "perm_range = [1e-12,1e-10] # unit: m-2, range of permeability \n",
    " \n",
    "# configure prior thermal conductivity\n",
    "th_cond_mean = 2 # unit: W/(mK)-1, mean of prior thermal conductivity\n",
    "th_cond_sd = 0.3 # unit: W/(mK)-1, S.D. of prior thermal conductivity\n",
    "th_cond_range = [0.9, 3] # unit: W/(mK)-1, range of thermal conductivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part 2.3'></a>\n",
    "# 2.3 Configuration \n",
    "This section has the following functions: reading input file, loading python packages, declaring variables, creating folders to store the checking point files of PFLOTRAN and HDF5 file containing permeability and thermal conductivity at each time step.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T16:17:54.031667Z",
     "start_time": "2017-12-20T16:17:53.085498Z"
    }
   },
   "outputs": [],
   "source": [
    "# ------------Initialize Python packages to be used------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import shutil as shutil\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import h5py\n",
    "import util as util\n",
    "import subprocess \n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "#--------Read In User Specified Input------------------\n",
    "time_start = datetime.datetime.now()\n",
    "print('\\n Reading in User Specified Parameters.')\n",
    "finput = open(\"./src/user_specified_parameters.txt\", 'r')\n",
    "fpflotran = open(\"./dainput/1dthermal.in\", 'r')\n",
    "input_array = finput.readlines()\n",
    "pflotranin = fpflotran.readlines()\n",
    "finput.close()\n",
    "ftest = open(\"./src/test.txt\",'w')\n",
    "\n",
    "# Run lines of text file to define variables\n",
    "for line in input_array:\n",
    "    if \"obs_coord\" in line:\n",
    "        new_line = line.replace('= [','= np.array([') + ')' \n",
    "        exec(new_line)\n",
    "    elif \"path_to_obs_data\" in line:\n",
    "        new_line = line.replace('path_to_obs_data = ','obs = np.loadtxt(') + ')'\n",
    "        exec(new_line)\n",
    "    elif \"perm_range\" in line:\n",
    "        new_line = line.replace('= [','= np.array([') +')'\n",
    "        exec(new_line)\n",
    "    elif \"th_cond_range\" in line:\n",
    "        new_line = line.replace('= [','= np.array([') +')'\n",
    "        exec(new_line)\n",
    "    exec(line)\n",
    "print(' Done.')\n",
    "\n",
    "# create folder ./pflotran to store the PFLOTRAN related files\n",
    "subprocess.call(\"rm -rf ./pflotran\",stdin=None, stdout=None,stderr=None,shell=True)\n",
    "subprocess.call(\"mkdir ./pflotran\",stdin=None, stdout=None,stderr=None,shell=True)\n",
    "\n",
    "# declare the intermediate variables\n",
    "nz = int(hz/dz) # number of grid blocks \n",
    "z = (np.arange(-hz,0,dz)+np.arange(-hz+dz,dz,dz))/2\n",
    "init_hy_cond = np.random.normal(hy_cond_mean,hy_cond_sd,nreaz)\n",
    "np.savetxt(\"./figure/init_hy_cond.txt\",init_hy_cond)\n",
    "init_th_cond = np.random.normal(th_cond_mean,th_cond_sd,nreaz)\n",
    "init_perm = init_hy_cond*w_vis/w_den/g/day_to_sec\n",
    "\n",
    "for iperm,vperm in enumerate(init_perm):\n",
    "    if vperm < perm_range[0]: init_perm[iperm] = perm_range[0]\n",
    "    if vperm > perm_range[1]: init_perm[iperm] = perm_range[1]\n",
    " \n",
    "init_logperm = np.log(init_perm)\n",
    "init_logperm_sd = np.std(init_logperm)\n",
    "nobs = len(obs_coord)\n",
    "ntime = np.shape(obs)[0]-1\n",
    "obs_time = obs[:,0]\n",
    "\n",
    "perm = np.zeros((ntime,nreaz))\n",
    "perm[0,:] = init_perm\n",
    "th_cond = np.zeros((ntime,nreaz))\n",
    "th_cond[0,:] = init_th_cond\n",
    "simu_time = np.zeros((ntime,2))\n",
    "kalman_gain_output = np.zeros((mw_length,ntime))\n",
    "FNULL = open(os.devnull,'w')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part 2.4'></a>\n",
    "# 2.4 ES-MDA Workflow\n",
    "This section shows the entire workflow of how to implement ES-MDA to estimate the hydrologic exchanage flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for itime in range(0,ntime):\n",
    "    simu_time[itime,:] = np.array([itime*da_interval,(itime+1)*da_interval])\n",
    "    \n",
    "    collect_start = 0\n",
    "    if (itime>0):\n",
    "        collect_start = simu_time[itime-1,1]\n",
    "    \n",
    "    collect_index = np.where((obs_time > collect_start) & (obs_time <= simu_time[itime,1]))\n",
    "    collect_times = obs_time[collect_index]\n",
    "    ncollect = len(collect_index)\n",
    "    simu_ensemble = np.zeros((nobs*len(collect_times),nreaz))\n",
    "\n",
    "    for itera in range(0,niter):\n",
    "       util.GenerateDbase(itime,itera,nreaz,perm,th_cond)\n",
    "       \n",
    "       util.MakePflotranInput(pflotranin,simu_time,itime,ncollect,collect_times,da_interval)\n",
    "       \n",
    "       subprocess.call(\"./src/pflotran.sh {} {} {} \".format(nreaz,ncore,pflotran_exe),stdin=None, stdout=FNULL,stderr=None,shell=True)\n",
    "       \n",
    "       simu_ensemble = util.GenerateSimuEnsemble(nobs,obs_coord,z,nreaz,collect_times)\n",
    "\n",
    "       ftest.write(\"simu_ensemble is:{} \\n\".format(simu_ensemble))\n",
    "       obs_sd = obs_sd_ratio*np.delete(np.squeeze(obs[collect_index,:],axis=0),0,1)\n",
    "       obs_sd = obs_sd*(math.sqrt(alpha))\n",
    "\n",
    "       obs_ensemble = np.repeat(np.transpose(np.delete(obs[collect_index],0,1)),nreaz,1)+np.diag(obs_sd.flatten('C'))@np.random.normal(0,1,nreaz*nobs*ncollect).reshape(nobs*ncollect,nreaz)       \n",
    "       ftest.write(\"obs_sd is:{} \\n\".format(obs_sd))\n",
    "       \n",
    "       # update state vector\n",
    "       state_vector = np.zeros((2,nreaz))\n",
    "       state_vector[0,:] = np.log(perm[itime,:])\n",
    "       state_vector[1,:] = th_cond[itime,:]\n",
    "       \n",
    "       cov_state_simu = np.zeros((2,nobs))\n",
    "       cov_state_simu = np.cov(state_vector,simu_ensemble)[0:2,2:]\n",
    "       cov_simu = np.cov(simu_ensemble)\n",
    "       ftest.write(\"cov_state-simu is: {} \\n\".format(cov_state_simu))\n",
    "       ftest.write(\"cov_simu is: {}\".format(cov_simu))\n",
    "\n",
    "       if nobs == 1:\n",
    "         inv_cov_simuAddobs = np.array([1/(cov_simu+np.square(np.diag(obs_sd)))])\n",
    "       else:\n",
    "         inv_cov_simuAddobs = la.inv(cov_simu+np.square(np.diag(obs_sd)))    \n",
    "       \n",
    "       kalman_gain = cov_state_simu@inv_cov_simuAddobs\n",
    "                 \n",
    "       state_vector = state_vector+kalman_gain@(obs_ensemble-simu_ensemble)\n",
    "\n",
    "       perm[itime,:] = np.exp(state_vector[0,:]) # no +1\n",
    "       perm[itime,:][perm[itime,:]>perm_range[1]] = perm_range[1]\n",
    "       perm[itime,:][perm[itime,:]<perm_range[0]] = perm_range[0]\n",
    "       th_cond[itime,:] = state_vector[1,:]\n",
    "       th_cond[itime,:][th_cond[itime,:]>th_cond_range[1]] = th_cond_range[1]\n",
    "       th_cond[itime,:][th_cond[itime,:]<th_cond_range[0]] = th_cond_range[0]  \n",
    "            \n",
    "       if itime+1 == ntime: break\n",
    " \n",
    "       # prepare input for next timestep\n",
    "       perm[itime+1,:] = perm[itime,:]\n",
    "       th_cond[itime+1,:] = th_cond[itime,:]\n",
    "       ftest.write(\"perm[itime+1,:] is: {} \\n\".format(perm[itime+1,:]))\n",
    "       #disturb perm\n",
    "       perm_temp = np.log(perm[itime+1,:])\n",
    "       perm_temp = perm_temp+np.random.normal(0,np.sqrt(max(np.square(init_logperm_sd)-np.square(np.std(perm_temp)),0)),nreaz)\n",
    "       perm[itime+1,:] = np.exp(perm_temp)\n",
    "       perm[itime+1,:][perm[itime+1,:]>perm_range[1]] = perm_range[1]\n",
    "       perm[itime+1,:][perm[itime+1,:]<perm_range[0]] = perm_range[0]\n",
    "       \n",
    "       th_cond[itime+1,:] = th_cond[itime,:]+np.random.normal(0,np.sqrt(max(np.square(th_cond_sd)-np.square(np.std(th_cond[itime+1,:])),0)),nreaz)\n",
    "       th_cond[itime+1,:][th_cond[itime+1,:]>th_cond_range[1]] = th_cond_range[1]\n",
    "       th_cond[itime+1,:][th_cond[itime+1,:]<th_cond_range[0]] = th_cond_range[0]  \n",
    "              \n",
    "       np.savetxt(\"./figure/perm.txt\",perm)\n",
    "\n",
    "time_end = datetime.datetime.now()\n",
    "time_cost = time_end-time_start\n",
    "with open(\"timecost.txt\", mode='w') as file:\n",
    "    file.write('%s.\\n'.format(timecost))\n",
    "fpflotran.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part 2.5'></a>\n",
    "# 2.5 PFLOTRAN related functions\n",
    "1. MakePflotranInput: update PFLOTRAN input file at each time step. The updated input file is put in the directory of ./pflotran along with the checkpoint files at each time step and HDF5 file storing permeability and thermal conductivity\n",
    "2. GenerateDbase: creat two new datasets for estimated permeability and thermal conductivity at each time step in the Dbase.h5 file.\n",
    "3. GenerateSimuEnsemble: read the simulated data (temperatures at the sensor depths) from the hdf5 file generated by PFLOTRAN at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T16:17:54.186276Z",
     "start_time": "2017-12-20T16:17:54.078653Z"
    }
   },
   "outputs": [],
   "source": [
    "def MakePflotranInput(pflotranin,simu_time,itime,ncollect,collect_times,da_interval):   \n",
    "    restart_lindex = [i for i, s in enumerate(pflotranin) if \"RESTART\" in s][0]\n",
    "    restart_card = [\"  RESTART \\n\",\n",
    "                       \"    FILENAME 1dthermal-restart.chk \\n\",\n",
    "                       \"    REALIZATION_DEPENDENT \\n\",\n",
    "\t\t       \"/ \\n\"]\n",
    "    if simu_time[itime,0] == 0:\n",
    "        pflotranin = pflotranin[0:restart_lindex]+pflotranin[restart_lindex+1:]\n",
    "    else:\n",
    "        pflotranin = pflotranin[0:restart_lindex]+restart_card+pflotranin[restart_lindex+1:]\n",
    "    \n",
    "    # write the end time of simulation\n",
    "    finaltime_lindex = [i for i, s in enumerate(pflotranin) if \"FINAL_TIME\" in s][0]\n",
    "    pflotranin[finaltime_lindex] = \"  FINAL_TIME \"+ np.array_str(simu_time[itime,1])+\" sec\"+\"\\n\"\n",
    "    \n",
    "    # generate observation \n",
    "    snapshot_lindex =  [i for i, s in enumerate(pflotranin) if \"SNAPSHOT_FILE\" in s][0]\n",
    "    obs_card = \"    TIMES sec   \"\n",
    "    npl = 3 \n",
    "    nline = np.floor_divide(ncollect,npl)\n",
    "    if nline == 0 or nline == 1:\n",
    "        obs_card = obs_card+\" \"+np.array_str(collect_times[0])+\"\\n\"\n",
    "    else:\n",
    "        for iline in range(1,nline):\n",
    "            obs_card = obs_card+np.array_str(collect_times[((iline-1)*npl+1):(iline*npl)])+\"\\\\\"\n",
    "        obs_card = obs_card+\" \"+np.array_str(collect_times[(iline*npl+1):ncollect])+\"\\n\"\n",
    "    \n",
    "    # add observation time\n",
    "    pflotranin = pflotranin[0:snapshot_lindex+1]+[obs_card]+pflotranin[snapshot_lindex+2:]     \n",
    "    \n",
    "    permiso_lindex = [i for i, s in enumerate(pflotranin) if \"PERM_ISO\" in s][0]\n",
    "    pflotranin[permiso_lindex] = \"    PERM_ISO DBASE_VALUE Permeability{} \\n\".format(itime)\n",
    "    \n",
    "    thercondwet_lindex = [i for i, s in enumerate(pflotranin) if \"THERMAL_CONDUCTIVITY_WET\" in s][0]\n",
    "    pflotranin[thercondwet_lindex] = \"  THERMAL_CONDUCTIVITY_WET DBASE_VALUE ThermalConductivity{} \\n\".format(itime)\n",
    "           \n",
    "    #prepare strata_card\n",
    "    strata_card_lindex = [i for i, s in enumerate(pflotranin) if \"STRATA\" in s][0]-1\n",
    "    strata_card = [\"STRATA\\n\",\n",
    "                   \"  REGION all\\n\",\n",
    "                   \"  MATERIAL Alluvium\\n\",\n",
    "                   \"  START_TIME 0 sec\\n\",\n",
    "                   \"  FINAL_TIME 0 sec\\n\",\n",
    "                   \"END\\n\",\n",
    "                   \"\\n\"]\n",
    "    strata_card_length = len(strata_card)\n",
    "    strata_card_new = list()    \n",
    "    strata_card[4] = \"  FINAL_TIME \"+str(da_interval*(itime+1))+\" sec\"+\"\\n\"\n",
    "    strata_card_copy = strata_card[:]\n",
    "    strata_card_new = strata_card_new+strata_card_copy\n",
    "        \n",
    "    pflotranin = pflotranin[0:strata_card_lindex]+strata_card_new+pflotranin[strata_card_lindex+strata_card_length:]\n",
    "    \n",
    "    new_pflotranin = open(\"./pflotran/1dthermal.in\",'w')\n",
    "    new_pflotranin.writelines(pflotranin)  \n",
    "    new_pflotranin.close()\n",
    "    return\n",
    "\n",
    "def GenerateDbase(itime,itera,nreaz,perm,th_cond):\n",
    "    filename = \"./pflotran/Dbase.h5\"\n",
    "    if itime == 0:\n",
    "      h5file = h5py.File(filename,'w')\n",
    "    else:\n",
    "      h5file = h5py.File(filename,'r+')\n",
    "      \n",
    "    variables = []\n",
    "    variables.append(\"Permeability{}\".format(itime))\n",
    "    variables.append(\"ThermalConductivity{}\".format(itime))\n",
    "    values = []\n",
    "    values.append(perm[itime,:])\n",
    "    values.append(th_cond[itime,:])\n",
    "    if itera == 0:\n",
    "      for i in range(len(variables)):\n",
    "        h5dset = h5file.create_dataset(variables[i],data=values[i])\n",
    "    else:\n",
    "      for i in range(len(variables)):\n",
    "        if h5file.get(variables[i]):\n",
    "          del h5file[variables[i]]\n",
    "        h5dset = h5file.create_dataset(variables[i],data=values[i])\n",
    "    h5file.close() \n",
    "    return\n",
    "                          \n",
    "def GenerateSimuEnsemble(nobs,obs_coord,z,nreaz,collect_times):\n",
    "    obs_cell = np.zeros(nobs)\n",
    "    for i in range(nobs):\n",
    "        obs_cell[i] = np.argmin(np.absolute(z-obs_coord[i]))\n",
    "    obs_cell = obs_cell.astype(int)\n",
    "    \n",
    "    simu_ensemble = np.zeros((nobs*len(collect_times),nreaz))\n",
    "    for ireaz in range(nreaz):\n",
    "        obs_temp = np.zeros(nobs*len(collect_times))\n",
    "        jj = 0\n",
    "        for collect_itime in collect_times:\n",
    "            h5f = h5py.File(\"./pflotran/1dthermalR{}.h5\".format(ireaz+1),'r')\n",
    "            grp_time = \"Time:\"+str(\" %12.5E\" % collect_itime)+\" s\"\n",
    "            dset_temp = \"Temperature [C]\"\n",
    "            obs_temp[jj*nobs:(jj+1)*nobs] = h5f[grp_time][dset_temp][0][0][obs_cell]\n",
    "            jj = jj+1\n",
    "        simu_ensemble[:,ireaz] = obs_temp\n",
    "        h5f.close()\n",
    "    \n",
    "    return simu_ensemble"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "982px",
   "left": "0px",
   "right": "auto",
   "top": "106px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
